{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pickle\n",
    "import re\n",
    "from functools import lru_cache\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.wrappers.fasttext import FastTextKeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "from joblib import Parallel, delayed\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"185/model.bin\", binary=True)\n",
    "\n",
    "w2v_vectors.vocab = dict(zip(list(map(lambda x: x.split('_')[0], w2v_vectors.vocab.keys())), w2v_vectors.vocab.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morph analyzer for text lemmatization\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "# function for performing parallel computing on cpu\n",
    "def parallelization(func, massive, jobs=None, tq=True):\n",
    "    num_cores = multiprocessing.cpu_count() if jobs is None else jobs\n",
    "    if tq:\n",
    "        results = np.array(Parallel(n_jobs=num_cores)(delayed(func)(i) for i in tqdm(massive)))\n",
    "        return results\n",
    "    else:\n",
    "        results = Parallel(n_jobs=num_cores)(delayed(func)(i) for i in massive)\n",
    "        return results\n",
    "\n",
    "\n",
    "def _word2canonical4w2v(word):\n",
    "    elems = morph.parse(word)\n",
    "    my_tag = ''\n",
    "    res = []\n",
    "    for elem in elems:\n",
    "        if 'VERB' in elem.tag or 'GRND' in elem.tag or 'INFN' in elem.tag:\n",
    "            my_tag = 'V'\n",
    "        if 'NOUN' in elem.tag:\n",
    "            my_tag = 'S'\n",
    "        normalised = elem.normalized.word\n",
    "        res.append((normalised, my_tag))\n",
    "    tmp = list(filter(lambda x: x[1] != '', res))\n",
    "    if len(tmp) > 0:\n",
    "        return tmp[0]\n",
    "    else:\n",
    "        return res[0]\n",
    "\n",
    "\n",
    "def word2canonical(word):\n",
    "    return _word2canonical4w2v(word)[0]\n",
    "\n",
    "\n",
    "def get_words(text, filter_short_words=False):\n",
    "    if filter_short_words:\n",
    "        return filter(lambda x: len(x) > 3, re.findall(r'(?u)\\w+', text))\n",
    "    else:\n",
    "        return re.findall(r'(?u)\\w+', text)\n",
    "\n",
    "\n",
    "def text2canonicals(text, add_word=False, filter_short_words=True):\n",
    "    words = []\n",
    "    for word in get_words(text, filter_short_words=filter_short_words):\n",
    "        words.append(word2canonical(word.lower()))\n",
    "        if add_word:\n",
    "            words.append(word.lower())\n",
    "    return words\n",
    "\n",
    "\n",
    "def preprocess(texts, dump=True):\n",
    "    preprocessed_texts = parallelization(text2canonicals, texts)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    texts = list(map(lambda x: ' '.join(x), preprocessed_texts))\n",
    "\n",
    "    if dump:\n",
    "        vectorizer = vectorizer.fit(texts)\n",
    "        with open('pickles/vectorizer.pkl', 'wb') as f:\n",
    "            pickle.dump(vectorizer, f)\n",
    "    else:\n",
    "        with open('pickles/vectorizer.pkl', 'rb') as f:\n",
    "            vectorizer = pickle.load(f)\n",
    "            \n",
    "    tfifd_vectorized = vectorizer.transform(texts).toarray()\n",
    "    unique_words = list(map(lambda x: x[0], sorted(vectorizer.vocabulary_.items())))\n",
    "\n",
    "    all_vectors = get_text_vectors(unique_words)\n",
    "    weighted_embeddings = tfifd_vectorized @ all_vectors\n",
    "\n",
    "    del tfifd_vectorized, all_vectors\n",
    "    \n",
    "    return weighted_embeddings\n",
    "\n",
    "def preprocess_single_text(text):\n",
    "    # embedding vectors weighted with tfidf\n",
    "    preprocessed_text = text2canonicals(text)\n",
    "    length = len(preprocessed_text) if len(preprocessed_text) > 0 else 1\n",
    "    \n",
    "    preprocessed_text = ' '.join(preprocessed_text)\n",
    "    vectorizer = pickle.load(open('pickles/vectorizer.pkl', 'rb'))\n",
    "    tfifd_vectorized = vectorizer.transform([preprocessed_text]).toarray()\n",
    "    unique_words = list(map(lambda x: x[0], sorted(vectorizer.vocabulary_.items())))\n",
    "    \n",
    "    all_vectors = get_text_vectors(unique_words)\n",
    "    weighted_embeddings = tfifd_vectorized @ all_vectors\n",
    "    weighted_embeddings /= length\n",
    "    del tfifd_vectorized, all_vectors\n",
    "    \n",
    "    return weighted_embeddings\n",
    "\n",
    "def get_text_vectors(text):\n",
    "    cnt = 0\n",
    "    matrix = np.zeros((len(text), 300))\n",
    "    for i,word in enumerate(text):\n",
    "        try:\n",
    "            vector = w2v_vectors[word]\n",
    "        except KeyError:\n",
    "            cnt += 1\n",
    "            vector = np.zeros((300,))\n",
    "        matrix[i] = vector\n",
    "    #print('cached {} exeptions'.format(cnt))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_id</th>\n",
       "      <th>local_datetime</th>\n",
       "      <th>content</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>giving you money back. thanks</td>\n",
       "      <td>[giving, you, money, back, thanks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>giving you money back. thanks</td>\n",
       "      <td>[giving, you, money, back, thanks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>for Ivan's birthday</td>\n",
       "      <td>[for, ivan, birthday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>for Ivan's birthday</td>\n",
       "      <td>[for, ivan, birthday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>for Ivan's birthday</td>\n",
       "      <td>[for, ivan, birthday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sp_id local_datetime                        content  \\\n",
       "5      2     2018-04-06  giving you money back. thanks   \n",
       "6      2     2018-04-06  giving you money back. thanks   \n",
       "7      2     2018-04-06            for Ivan's birthday   \n",
       "8      2     2018-04-06            for Ivan's birthday   \n",
       "9      2     2018-04-06            for Ivan's birthday   \n",
       "\n",
       "                                lemma  \n",
       "5  [giving, you, money, back, thanks]  \n",
       "6  [giving, you, money, back, thanks]  \n",
       "7               [for, ivan, birthday]  \n",
       "8               [for, ivan, birthday]  \n",
       "9               [for, ivan, birthday]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = (pd\n",
    "            .read_pickle(\"data/new_data.pkl\")\n",
    "            .rename(columns={\"message\": \"content\"})\n",
    "            .assign(local_datetime = lambda x: x[\"local_datetime\"].str[:10])\n",
    "            .astype({\"local_datetime\": \"datetime64\"})\n",
    "            )\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33183/33183 [00:11<00:00, 2880.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_id</th>\n",
       "      <th>local_datetime</th>\n",
       "      <th>content</th>\n",
       "      <th>lemma</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>giving you money back. thanks</td>\n",
       "      <td>[giving, you, money, back, thanks]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>giving you money back. thanks</td>\n",
       "      <td>[giving, you, money, back, thanks]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>for Ivan's birthday</td>\n",
       "      <td>[for, ivan, birthday]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>for Ivan's birthday</td>\n",
       "      <td>[for, ivan, birthday]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>for Ivan's birthday</td>\n",
       "      <td>[for, ivan, birthday]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>for Ivan's birthday</td>\n",
       "      <td>[for, ivan, birthday]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>for Ivan's birthday</td>\n",
       "      <td>[for, ivan, birthday]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>Не забудь вернуть вз</td>\n",
       "      <td>[забыть, вернуть]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>Тестовый перевод себе</td>\n",
       "      <td>[тестовый, перевод, себя]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>Тестовый перевод себе попытка</td>\n",
       "      <td>[тестовый, перевод, себя, попытка]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>длодло</td>\n",
       "      <td>[длодло]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>привет</td>\n",
       "      <td>[привет]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>Oh yeah вз</td>\n",
       "      <td>[yeah]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>Ура вз</td>\n",
       "      <td>[ура]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>УРА вз</td>\n",
       "      <td>[ура]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>тебе на подарок</td>\n",
       "      <td>[ты, подарок]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>в подарок</td>\n",
       "      <td>[подарок]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>с райфа</td>\n",
       "      <td>[райф]</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>вапв</td>\n",
       "      <td>[вапть]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>ghg</td>\n",
       "      <td>[ghg]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>erter</td>\n",
       "      <td>[erter]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>opi</td>\n",
       "      <td>[opi]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>карочи</td>\n",
       "      <td>[кароко]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>привет</td>\n",
       "      <td>[привет]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>Ntcn</td>\n",
       "      <td>[ntcn]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>привет</td>\n",
       "      <td>[привет]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>raif</td>\n",
       "      <td>[raif]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>вапавп</td>\n",
       "      <td>[вапавп]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Alfa</td>\n",
       "      <td>[alfa]</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Alfa</td>\n",
       "      <td>[alfa]</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>чсмс</td>\n",
       "      <td>[чсмс]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>вуава</td>\n",
       "      <td>[вуава]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>апв</td>\n",
       "      <td>[апв]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>вавывп</td>\n",
       "      <td>[вавывп]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Лина любит Лину вз</td>\n",
       "      <td>[лина, любить, лина]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>ясчс</td>\n",
       "      <td>[ясчс]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>мачм</td>\n",
       "      <td>[мачм]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Уеба, бля вз</td>\n",
       "      <td>[уеб, бля]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Hello, world вз</td>\n",
       "      <td>[hello, world]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Hello, hello</td>\n",
       "      <td>[hello, hello]</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Тест</td>\n",
       "      <td>[тест]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Ping?</td>\n",
       "      <td>[ping]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>dfd</td>\n",
       "      <td>[dfd]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>dfd</td>\n",
       "      <td>[dfd]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>dfd</td>\n",
       "      <td>[dfd]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Это Тимофей</td>\n",
       "      <td>[это, тимофей]</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Ни в чем себе не отказывай, дорогая</td>\n",
       "      <td>[чем, себя, отказывать, дорогой]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>test</td>\n",
       "      <td>[test]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Привет</td>\n",
       "      <td>[привет]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>на ипотеку</td>\n",
       "      <td>[ипотека]</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-24</td>\n",
       "      <td>Ура_?:</td>\n",
       "      <td>[ура_]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sp_id local_datetime                        content  \\\n",
       "5        2     2018-04-06  giving you money back. thanks   \n",
       "6        2     2018-04-06  giving you money back. thanks   \n",
       "7        2     2018-04-06            for Ivan's birthday   \n",
       "8        2     2018-04-06            for Ivan's birthday   \n",
       "9        2     2018-04-06            for Ivan's birthday   \n",
       "..     ...            ...                            ...   \n",
       "130      2     2018-04-24                           test   \n",
       "131      2     2018-04-24                           test   \n",
       "132      2     2018-04-24                         Привет   \n",
       "133      2     2018-04-24                     на ипотеку   \n",
       "134      2     2018-04-24                         Ура_?:   \n",
       "\n",
       "                                  lemma  cluster  \n",
       "5    [giving, you, money, back, thanks]       43  \n",
       "6    [giving, you, money, back, thanks]       43  \n",
       "7                 [for, ivan, birthday]       43  \n",
       "8                 [for, ivan, birthday]       43  \n",
       "9                 [for, ivan, birthday]       43  \n",
       "..                                  ...      ...  \n",
       "130                              [test]       36  \n",
       "131                              [test]       36  \n",
       "132                            [привет]       14  \n",
       "133                           [ипотека]       45  \n",
       "134                              [ура_]        1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = preprocess(comments[\"content\"].values, dump=True)\n",
    "n_components = 50\n",
    "kmeans = KMeans(n_clusters=n_components, random_state=0).fit(vectors)\n",
    "with open('pickles/kmeans.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "comments = comments.assign(cluster = kmeans.labels_)\n",
    "comments.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random examples from clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster # 0\n",
      "                        content\n",
      "655202                     кофе\n",
      "555216  Саня балабанов за пивас\n",
      "435849               на тортики\n",
      "\n",
      "Cluster # 1\n",
      "                                   content\n",
      "677699                              За Мед\n",
      "491018  Миляуше Хамитовне Яна Хузягалеева \n",
      "630716                              Приват\n",
      "\n",
      "Cluster # 2\n",
      "                    content\n",
      "663395         На  Сентября\n",
      "556472  На  сентября + торт\n",
      "659166         За Сентябрь \n",
      "\n",
      "Cluster # 3\n",
      "       content\n",
      "58541    такси\n",
      "461611   такси\n",
      "417221   Такси\n",
      "\n",
      "Cluster # 4\n",
      "                 content\n",
      "543757           Спасибо\n",
      "587576  Спасибо вз вз вз\n",
      "406128        Спасибо вз\n",
      "\n",
      "Cluster # 5\n",
      "                           content\n",
      "620107        Алексей Валентинович\n",
      "407327  Цветная Людмила Алексеевна\n",
      "417183        Алексей Анатольевич \n",
      "\n",
      "Cluster # 6\n",
      "              content\n",
      "407824           Долг\n",
      "413810  Возврат Долга\n",
      "663075  Отдаю долг ❤️\n",
      "\n",
      "Cluster # 7\n",
      "                   content\n",
      "25174              перевод\n",
      "683420             перевод\n",
      "465483  Денежные переводы \n",
      "\n",
      "Cluster # 8\n",
      "                                         content\n",
      "550151                  Когда Получишь - Позвони\n",
      "449050                    Как Придут Набери Мне \n",
      "565714  привет Даша напиши если прийдут это Женя\n",
      "\n",
      "Cluster # 9\n",
      "                    content\n",
      "544748                 тебе\n",
      "423623                 Тебе\n",
      "106774   Люблю тебя милая. \n",
      "\n",
      "Cluster # 10\n",
      "                       content\n",
      "568028  От Александра Простор.\n",
      "469511                   Общаг\n",
      "427265             букет лавка\n",
      "\n",
      "Cluster # 11\n",
      "          content\n",
      "530462     Сергей\n",
      "499945    Сергей \n",
      "635325  От Сергея\n",
      "\n",
      "Cluster # 12\n",
      "                             content\n",
      "639902  Деньги За Ботинки.  От Глеба\n",
      "432774                        Деньги\n",
      "567272                        деньги\n",
      "\n",
      "Cluster # 13\n",
      "                               content\n",
      "399431  Дементьева Татьяна Дмитриевна \n",
      "462207     Горянина Татьяна Васильевна\n",
      "545867                         Татьяна\n",
      "\n",
      "Cluster # 14\n",
      "       content\n",
      "582924  привет\n",
      "516151  Привет\n",
      "625016  Привет\n",
      "\n",
      "Cluster # 15\n",
      "                               content\n",
      "425231      Касперу на бензин, бля....\n",
      "489745  Деньги за подставку для винила\n",
      "581614                  Как Получится \n",
      "\n",
      "Cluster # 16\n",
      "                  content\n",
      "591536        Доброе Утро\n",
      "57687    Вдруг не хватит \n",
      "501371              Христ\n",
      "\n",
      "Cluster # 17\n",
      "     content\n",
      "3637    text\n",
      "3889    text\n",
      "3634    text\n",
      "\n",
      "Cluster # 18\n",
      "                                               content\n",
      "536084  На День Строителя  Завьялов Максим  Человека. \n",
      "1078                                           Гаджиев\n",
      "410290                                        Лихачевы\n",
      "\n",
      "Cluster # 19\n",
      "                 content\n",
      "398897           подарок\n",
      "620874    Юле На Подарок\n",
      "410579  за подарок Насте\n",
      "\n",
      "Cluster # 20\n",
      "                                           content\n",
      "608987                                    От ОЛЬГИ\n",
      "416065                                       Ольга\n",
      "566780   для Светланы Сергеевнв от Ольги Назаренко\n",
      "\n",
      "Cluster # 21\n",
      "                   content\n",
      "419372  Переведены  рублей\n",
      "21769              перевёл\n",
      "547722            Перевела\n",
      "\n",
      "Cluster # 22\n",
      "       content\n",
      "586528   Лови \n",
      "580466   Лови \n",
      "389623   лови \n",
      "\n",
      "Cluster # 23\n",
      "                         content\n",
      "570260      Евстиферов Михаил -.\n",
      "502988  Фрыгин Михаил Сергеевич \n",
      "5662              От Кристины С.\n",
      "\n",
      "Cluster # 24\n",
      "         content\n",
      "22067    от мамы\n",
      "432394   к маме \n",
      "550478   От Мамы\n",
      "\n",
      "Cluster # 25\n",
      "         content\n",
      "569264      себе\n",
      "661681     Себе \n",
      "472385  Сам Себе\n",
      "\n",
      "Cluster # 26\n",
      "         content\n",
      "814      тест вз\n",
      "342066  Тест афт\n",
      "3621        тест\n",
      "\n",
      "Cluster # 27\n",
      "                       content\n",
      "546022   напиши когда получишь\n",
      "433945                получили\n",
      "622184        Получил Позвони.\n",
      "\n",
      "Cluster # 28\n",
      "       content\n",
      "405445   Проба\n",
      "434039   Проба\n",
      "569558   Проба\n",
      "\n",
      "Cluster # 29\n",
      "                     content\n",
      "684586           для Кирилла\n",
      "523867                Виктор\n",
      "257279   Елена Геннадьевна М\n",
      "\n",
      "Cluster # 30\n",
      "         content\n",
      "417124  проверка\n",
      "522681  проверка\n",
      "445290  проверка\n",
      "\n",
      "Cluster # 31\n",
      "                        content\n",
      "580218              За Сигареты\n",
      "247752              За сигареты\n",
      "577336   За сигареты.Геофизика)\n",
      "\n",
      "Cluster # 32\n",
      "                    content\n",
      "429313   thonybug@gmail.com\n",
      "52236                Happy \n",
      "348761  Taxi - Vernadskogo \n",
      "\n",
      "Cluster # 33\n",
      "                              content\n",
      "464410  За Раевского Влада Июнь, Июль\n",
      "526004                           Корм\n",
      "432292                       за мойку\n",
      "\n",
      "Cluster # 34\n",
      "           content\n",
      "484309        Миша\n",
      "649920   Екатерине\n",
      "599859  От Тамары)\n",
      "\n",
      "Cluster # 35\n",
      "                                     content\n",
      "637417  проверка новой карты перевод  рублей\n",
      "594584                                Фактор\n",
      "659242                   Благотворительность\n",
      "\n",
      "Cluster # 36\n",
      "       content\n",
      "1541      test\n",
      "501306   Test \n",
      "53        test\n",
      "\n",
      "Cluster # 37\n",
      "               content\n",
      "562372  Проверка Связи\n",
      "537271  Проверка Связи\n",
      "606539  Проверка Связи\n",
      "\n",
      "Cluster # 38\n",
      "          content\n",
      "50435    На цветы\n",
      "400032   За цветы\n",
      "624143      Цветы\n",
      "\n",
      "Cluster # 39\n",
      "                                                  content\n",
      "651338                    С Днём Рождения И Рождения Сына\n",
      "615640  Светик, На Маленькие Радости)) С Прошедшим Днё...\n",
      "602307                     С Днем Рождения вз Тётя Оксана\n",
      "\n",
      "Cluster # 40\n",
      "                  content\n",
      "525084             Оплата\n",
      "613879             Оплата\n",
      "2314    На оплату вытяжки\n",
      "\n",
      "Cluster # 41\n",
      "                content\n",
      "613289   Молодых Элина \n",
      "82820    привет,атай вз\n",
      "396331             влад\n",
      "\n",
      "Cluster # 42\n",
      "                         content\n",
      "494909           ...пока Так....\n",
      "404338           спасибо за обед\n",
      "531119    спасибо парвиз, ДимаМ.\n",
      "\n",
      "Cluster # 43\n",
      "         content\n",
      "51888    payment\n",
      "561050      love\n",
      "605502    ANDREY\n",
      "\n",
      "Cluster # 44\n",
      "          content\n",
      "44955    рахмат )\n",
      "656422    Рахмат \n",
      "475101    Рахмат \n",
      "\n",
      "Cluster # 45\n",
      "                       content\n",
      "613335  Предоплата От Антипова\n",
      "407518              С Аванса )\n",
      "1985        доплата по кредиту\n",
      "\n",
      "Cluster # 46\n",
      "              content\n",
      "533684      Страховка\n",
      "533665      Страховка\n",
      "540107   за страховку\n",
      "\n",
      "Cluster # 47\n",
      "                                                 content\n",
      "179290                              Выпускной за Ясакову\n",
      "606255                                         на отпуск\n",
      "675980  Галя Поздравляю Данечку с началом учебного года \n",
      "\n",
      "Cluster # 48\n",
      "                       content\n",
      "53037    за квартиру Булякова \n",
      "551036             За Квартиру\n",
      "616601                Квартира\n",
      "\n",
      "Cluster # 49\n",
      "                               content\n",
      "611524   Спасибо. Володя это за Прадик\n",
      "655412                  От Люси И Паши\n",
      "280045                за илью борисова\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clusters in range(n_components):\n",
    "    print('Cluster #', clusters)\n",
    "    try:\n",
    "        print(comments.query('cluster == @clusters').sample(3, random_state=0)[['content']])\n",
    "    except ValueError:\n",
    "        print(comments.query('cluster == @clusters').sample(3, random_state=0, replace=True)[['content']])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_names = {\n",
    "    0: \"Обед\",\n",
    "    1: \"Спасибо\",\n",
    "    2: \"Привет\",\n",
    "    3: \"Перевод\",\n",
    "    4: \"Покупка\",\n",
    "    5: \"Мало\",\n",
    "    6: \"Центральный\",\n",
    "    7: \"Деньги\",\n",
    "    8: \"Люблю\",\n",
    "    9: \"Квартира\",\n",
    "    10: \"Шаурма\",\n",
    "    11: \"иммя\",\n",
    "    12: \"иммя\",\n",
    "    13: \"test\",\n",
    "    14: \"иммя\",\n",
    "    15: \"Такси\",\n",
    "    16: \"Тест\",\n",
    "    17: \"Проверка связи\",\n",
    "    18: \"Штраф\",\n",
    "    19: \"Стол\",\n",
    "    20: \"иммя\",\n",
    "    21: \"Костюм\",\n",
    "    22: \"Долг\",\n",
    "    23: \"Подарок\",\n",
    "    24: \"Возврат\",\n",
    "    25: \"иммя\",\n",
    "    26: \"Себе\",\n",
    "    27: \"Оплата\",\n",
    "    28: \"Проба\",\n",
    "    29: \"иммя\",\n",
    "    30: \"Подарки\",\n",
    "    31: \"иммя\",\n",
    "    32: \"Лови\",\n",
    "    33: \"Перевёл\",\n",
    "    34: \"С Днём рождения\",\n",
    "    35: \"Мама\",\n",
    "    36: \"На счёт\",\n",
    "    37: \"иммя\",\n",
    "    38: \"Проезд\",\n",
    "    39: \"Пиво\",\n",
    "    40: \"Пришли?\",\n",
    "    41: \"иммя\",\n",
    "    42: \"Мойка\",\n",
    "    43: \"Кредит\",\n",
    "    44: \"иммя\",\n",
    "    45: \"Проверка\",\n",
    "    46: \"иммя\",\n",
    "    47: \"Напиши если пришли\",\n",
    "    48: \"иммя\",\n",
    "    49: \"иммя\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# map_clusters = lambda x: 0 if clusters_names[x] == \"иммя\" else x\n",
    "# comments[\"cluster_fixed\"] = comments[\"cluster\"].map(map_clusters)\n",
    "\n",
    "# comments[\"cluster_name\"] = comments[\"cluster\"].map(clusters_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# comments.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comments.to_pickle(\"pickles/comments.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cluster and random comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cluster_analysis.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import re\n",
    "from functools import lru_cache\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.wrappers.fasttext import FastTextKeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "from joblib import Parallel, delayed\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Start service with these models in memory\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"185/model.bin\", binary=True)\n",
    "w2v_vectors.vocab = dict(zip(list(map(lambda x: x.split('_')[0], w2v_vectors.vocab.keys())), w2v_vectors.vocab.values()))\n",
    "kmeans = pickle.load(open('pickles/kmeans.pkl', 'rb'))\n",
    "comments = pickle.load(open('pickles/comments.pkl', 'rb'))\n",
    "# morph analyzer for text lemmatization\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "# function for performing parallel computing on cpu\n",
    "def parallelization(func, massive, jobs=None, tq=True):\n",
    "    num_cores = multiprocessing.cpu_count() if jobs is None else jobs\n",
    "    if tq:\n",
    "        results = np.array(Parallel(n_jobs=num_cores)(delayed(func)(i) for i in tqdm(massive)))\n",
    "        return results\n",
    "    else:\n",
    "        results = Parallel(n_jobs=num_cores)(delayed(func)(i) for i in massive)\n",
    "        return results\n",
    "\n",
    "\n",
    "def _word2canonical4w2v(word):\n",
    "    elems = morph.parse(word)\n",
    "    my_tag = ''\n",
    "    res = []\n",
    "    for elem in elems:\n",
    "        if 'VERB' in elem.tag or 'GRND' in elem.tag or 'INFN' in elem.tag:\n",
    "            my_tag = 'V'\n",
    "        if 'NOUN' in elem.tag:\n",
    "            my_tag = 'S'\n",
    "        normalised = elem.normalized.word\n",
    "        res.append((normalised, my_tag))\n",
    "    tmp = list(filter(lambda x: x[1] != '', res))\n",
    "    if len(tmp) > 0:\n",
    "        return tmp[0]\n",
    "    else:\n",
    "        return res[0]\n",
    "\n",
    "\n",
    "def word2canonical(word):\n",
    "    return _word2canonical4w2v(word)[0]\n",
    "\n",
    "\n",
    "def get_words(text, filter_short_words=False):\n",
    "    if filter_short_words:\n",
    "        return filter(lambda x: len(x) > 3, re.findall(r'(?u)\\w+', text))\n",
    "    else:\n",
    "        return re.findall(r'(?u)\\w+', text)\n",
    "\n",
    "\n",
    "def text2canonicals(text, add_word=False, filter_short_words=True):\n",
    "    words = []\n",
    "    for word in get_words(text, filter_short_words=filter_short_words):\n",
    "        words.append(word2canonical(word.lower()))\n",
    "        if add_word:\n",
    "            words.append(word.lower())\n",
    "    return words\n",
    "\n",
    "\n",
    "def preprocess(texts, dump=True):\n",
    "    preprocessed_texts = parallelization(text2canonicals, texts)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    texts = list(map(lambda x: ' '.join(x), preprocessed_texts))\n",
    "\n",
    "    if dump:\n",
    "        vectorizer = vectorizer.fit(texts)\n",
    "        with open('pickles/vectorizer.pkl', 'wb') as f:\n",
    "            pickle.dump(vectorizer, f)\n",
    "    else:\n",
    "        with open('pickles/vectorizer.pkl', 'rb') as f:\n",
    "            vectorizer = pickle.load(f)\n",
    "            \n",
    "    tfifd_vectorized = vectorizer.transform(texts).toarray()\n",
    "    unique_words = list(map(lambda x: x[0], sorted(vectorizer.vocabulary_.items())))\n",
    "\n",
    "    all_vectors = get_text_vectors(unique_words)\n",
    "    weighted_embeddings = tfifd_vectorized @ all_vectors\n",
    "\n",
    "    del tfifd_vectorized, all_vectors\n",
    "    \n",
    "    return weighted_embeddings\n",
    "\n",
    "def preprocess_single_text(text):\n",
    "    # embedding vectors weighted with tfidf\n",
    "    preprocessed_text = text2canonicals(text)\n",
    "    length = len(preprocessed_text) if len(preprocessed_text) > 0 else 1\n",
    "    \n",
    "    preprocessed_text = ' '.join(preprocessed_text)\n",
    "    vectorizer = pickle.load(open('pickles/vectorizer.pkl', 'rb'))\n",
    "    tfifd_vectorized = vectorizer.transform([preprocessed_text]).toarray()\n",
    "    unique_words = list(map(lambda x: x[0], sorted(vectorizer.vocabulary_.items())))\n",
    "    \n",
    "    all_vectors = get_text_vectors(unique_words)\n",
    "    weighted_embeddings = tfifd_vectorized @ all_vectors\n",
    "    weighted_embeddings /= length\n",
    "    del tfifd_vectorized, all_vectors\n",
    "    \n",
    "    return weighted_embeddings\n",
    "\n",
    "def get_text_vectors(text):\n",
    "    cnt = 0\n",
    "    matrix = np.zeros((len(text), 300))\n",
    "    for i,word in enumerate(text):\n",
    "        try:\n",
    "            vector = w2v_vectors[word]\n",
    "        except KeyError:\n",
    "            cnt += 1\n",
    "            vector = np.zeros((300,))\n",
    "        matrix[i] = vector\n",
    "    #print('cached {} exeptions'.format(cnt))\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def infer_cluster(text):\n",
    "    vector = preprocess_single_text(text)\n",
    "    cluster = kmeans.predict(vector)\n",
    "    try:\n",
    "        random_3 = comments.query('cluster == @cluster').sample(3, random_state=0)['content'].to_list()\n",
    "    except ValueError:\n",
    "        random_3 = comments.query('cluster == @cluster').sample(3, random_state=0, replace=True).to_list()\n",
    "    return cluster[0], random_3\n",
    "\n",
    "\n",
    "def get_top_clusters_overall(comments=comments):\n",
    "    cluster_frequencies = (comments[\"cluster\"]\n",
    "                           .value_counts()[:3]\n",
    "                           .map(lambda x: str(round(x/len(comments) * 100, 1))+\"%\")\n",
    "                           .to_dict()\n",
    "                           )\n",
    "    return cluster_frequencies\n",
    "\n",
    "\n",
    "def get_top_clusters_month(comments=comments):\n",
    "    comments = comments[(comments[\"local_datetime\"].dt.month) == 7 & (comments[\"local_datetime\"].dt.year == 2019)]\n",
    "    cluster_frequencies = (comments[\"cluster\"]\n",
    "                           .value_counts()[:3]\n",
    "                           .map(lambda x: str(round(x/len(comments) * 100, 1))+\"%\")\n",
    "                           .to_dict()\n",
    "                           )\n",
    "    return cluster_frequencies\n",
    "\n",
    "\n",
    "def get_top_clusters_week(comments=comments):\n",
    "    comments = comments[(\"2019-07-25\" <= comments[\"local_datetime\"]) & (comments[\"local_datetime\"] <= \"2019-07-31\")]\n",
    "    cluster_frequencies = (comments[\"cluster\"]\n",
    "                           .value_counts()[:3]\n",
    "                           .map(lambda x: str(round(x / len(comments) * 100, 1))+\"%\")\n",
    "                           .to_dict()\n",
    "                           )\n",
    "    return cluster_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluster_analysis import infer_cluster as infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       content\n",
      "53037    за квартиру Булякова \n",
      "551036             За Квартиру\n",
      "616601                Квартира\n"
     ]
    }
   ],
   "source": [
    "clust = 48\n",
    "try:\n",
    "    print(comments.query('cluster == @clust').sample(3, random_state=0)[['content']])\n",
    "except ValueError:\n",
    "    print(comments.query('cluster == @clust').sample(3, random_state=0, replace=True)[['content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster(text):\n",
    "    vector = preprocess_single_text(text)\n",
    "    cluster = kmeans.predict(vector)\n",
    "    try:\n",
    "        random_3 = comments.query('cluster == @cluster').sample(3, random_state=0)['content'].to_list()\n",
    "    except ValueError:\n",
    "        random_3 = comments.query('cluster == @cluster').sample(3, random_state=0, replace=True).to_list()\n",
    "    return cluster[0], random_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, [' за квартиру Булякова ', 'За Квартиру', 'Квартира'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(\"За Квартиру плт\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster frequency lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '19.3%', 15: '7.4%', 41: '6.6%'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[\"cluster\"].value_counts()[:3].map(lambda x: str(round(x/len(comments) * 100, 1))+\"%\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clusters_overall(comments=comments):\n",
    "    cluster_frequencies = (comments[\"cluster\"]\n",
    "                           .value_counts()[:3]\n",
    "                           .map(lambda x: str(round(x/len(comments) * 100, 1))+\"%\")\n",
    "                           .to_dict()\n",
    "                           )\n",
    "    return cluster_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '19.3%', 15: '7.4%', 41: '6.6%'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_clusters_overall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clusters_month(comments=comments):\n",
    "    comments = comments[(comments[\"local_datetime\"].dt.month) == 7 & (comments[\"local_datetime\"].dt.year == 2019)]\n",
    "    cluster_frequencies = (comments[\"cluster\"]\n",
    "                           .value_counts()[:3]\n",
    "                           .map(lambda x: str(round(x/len(comments) * 100, 1))+\"%\")\n",
    "                           .to_dict()\n",
    "                           )\n",
    "    return cluster_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '23.2%', 41: '7.8%', 15: '6.9%'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_clusters_month()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clusters_week(comments=comments):\n",
    "    comments = comments[(\"2019-07-25\" <= comments[\"local_datetime\"]) & (comments[\"local_datetime\"] <= \"2019-07-31\")]\n",
    "    cluster_frequencies = (comments[\"cluster\"]\n",
    "                           .value_counts()[:3]\n",
    "                           .map(lambda x: str(round(x/len(comments) * 100, 1))+\"%\")\n",
    "                           .to_dict()\n",
    "                           )\n",
    "    return cluster_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '20.3%', 15: '7.5%', 41: '7.5%'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_clusters_week()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
